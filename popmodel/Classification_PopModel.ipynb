{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Popmodel - Classification Modelling\n",
    "##### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import OrdinalEncoder, KBinsDiscretizer, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_validate\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from xgboost import XGBClassifier, XGBRFClassifier\n",
    "import imblearn"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Notebook Settings"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "sns.set_style(\"whitegrid\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Feature Engineering"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "#Read CSVs\n",
    "data = pd.read_csv(\"SpotifyData.csv\")\n",
    "add_infos = pd.read_csv(\"additional_infos.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Adjust inconsistent genre naming\n",
    "data.loc[data[\"genre\"] == 'Childrenâ€™s Music', \"genre\"] = \"Children Music\"\n",
    "data.loc[data[\"genre\"] == \"Children's Music\", \"genre\"] = \"Children Music\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Join duplicate tracks assigned to different genres together in one common row\n",
    "genre_df = data.groupby(['track_id'])['genre'].apply(', '.join).reset_index()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Drop duplicates by track ID and remove ID column\n",
    "data.drop_duplicates(\"track_id\", inplace=True)\n",
    "data.sort_values(\"track_id\", inplace=True)\n",
    "data.reset_index(inplace=True, drop=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Assign Features\n",
    "X = data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Replace genre column in original dataset\n",
    "X[\"genre\"] = genre_df[\"genre\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Genre encoding seperate since there can be multiple values in one row\n",
    "X = pd.concat([X, X['genre'].str.get_dummies(sep=', ')], axis=1)\n",
    "X = pd.concat([X, pd.get_dummies(X[[\"key\",\"mode\",\"time_signature\"]])], axis=1)\n",
    "X.drop([\"key\",\"mode\",\"time_signature\",\"genre\"], axis=1, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Add explicit feature from external dataset\n",
    "add_infos.sort_values(\"id\", inplace=True)\n",
    "assert pd.Series(add_infos[\"id\"].values == X[\"track_id\"].values).value_counts().values[0] == len(add_infos)\n",
    "X[\"explicit\"] = add_infos[\"explicit\"]\n",
    "X[\"track_number\"] = add_infos[\"track_number\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Get release Date from String and create new feature\n",
    "temp = []\n",
    "for i in range(len(add_infos)):\n",
    "    temp += [int(add_infos[\"album\"][i][add_infos[\"album\"][i].find(\"release_date\") + 16: add_infos[\"album\"][i].find(\"release_date\") + 20])]\n",
    "X[\"release_date\"] = temp\n",
    "X.loc[X[\"release_date\"] == 0000, \"release_date\"] = X[\"release_date\"].values.mean().round()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Get total track number from String and create new feature\n",
    "temp = []\n",
    "for i in range(len(add_infos)):\n",
    "    if add_infos[\"album\"][i][add_infos[\"album\"][i].find(\"total_tracks\") + 16] == \",\":\n",
    "        temp += [int(add_infos[\"album\"][i][add_infos[\"album\"][i].find(\"total_tracks\") + 15: add_infos[\"album\"][i].find(\"total_tracks\") + 16])]\n",
    "    elif add_infos[\"album\"][i][add_infos[\"album\"][i].find(\"total_tracks\") + 17] == \",\":\n",
    "        temp += [int(add_infos[\"album\"][i][add_infos[\"album\"][i].find(\"total_tracks\") + 15: add_infos[\"album\"][i].find(\"total_tracks\") + 17])]\n",
    "    else:\n",
    "        temp += [int(add_infos[\"album\"][i][add_infos[\"album\"][i].find(\"total_tracks\") + 15: add_infos[\"album\"][i].find(\"total_tracks\") + 18])]\n",
    "X[\"total_tracks\"] = temp"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Get artist id from String and create new feature\n",
    "temp = []\n",
    "for i in range(len(add_infos)):\n",
    "    temp += [add_infos[\"album\"][i][add_infos[\"album\"][i].find(\"id\") + 6: add_infos[\"album\"][i].find(\"id\") + 28]]\n",
    "X[\"artist_id\"] = temp"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Drop Songs with zero popularity\n",
    "X.drop(X[X[\"popularity\"] == 0].index, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Drop voice only audio tracks\n",
    "X.drop(X[X[\"speechiness\"] > 0.70].index, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#encoding track id and artist\n",
    "lenc = OrdinalEncoder()\n",
    "X[\"track_id\"] = lenc.fit_transform(X[\"track_id\"].values.reshape(-1,1))\n",
    "X[\"artist_id\"] = lenc.fit_transform(X[\"artist_id\"].values.reshape(-1,1))\n",
    "X[\"track_name\"] = lenc.fit_transform(X[\"track_name\"].values.reshape(-1,1))\n",
    "X[\"artist_name\"] = lenc.fit_transform(X[\"artist_name\"].values.reshape(-1,1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# OR! drop the former columns\n",
    "X.drop([\"track_id\", \"artist_name\", \"track_name\", \"artist_id\"], axis=1, inplace=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#reset index\n",
    "X.reset_index(inplace=True)\n",
    "X.drop(\"index\", axis=1, inplace=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Assign Prediction Target\n",
    "y = X[\"popularity\"]\n",
    "X.drop([\"popularity\"], axis=1, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Class binning of y into three classes of the same size\n",
    "est = KBinsDiscretizer(n_bins=3, encode='ordinal', strategy='uniform')\n",
    "y = pd.DataFrame(est.fit_transform(y.values.reshape(-1, 1)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Scaling all features (Brings less accuracy)\n",
    "minni = MinMaxScaler()\n",
    "pd.DataFrame(minni.fit_transform(X))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Models"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Validation Set\n",
    "X_valid = X.sample(frac=0.1,random_state=1, replace=False)\n",
    "X.drop(X_valid.index, inplace=True)\n",
    "\n",
    "y_valid = y.iloc[X_valid.index]\n",
    "y.drop(y_valid.index, inplace=True)\n",
    "\n",
    "X.reset_index(inplace=True, drop=True)\n",
    "y.reset_index(inplace=True, drop=True)\n",
    "X_valid.reset_index(inplace=True, drop=True)\n",
    "y_valid.reset_index(inplace=True, drop=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Train Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=3, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Over and undersampling of training data (Decreases Scores)\n",
    "smote = imblearn.over_sampling.SMOTE(sampling_strategy='minority', random_state=3, n_jobs=-1)\n",
    "X_train, y_train = smote.fit_resample(X_train,y_train)\n",
    "len(X)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#PopModel\n",
    "rfc = RandomForestClassifier(min_samples_split=11, verbose=0, n_jobs=-1, random_state=3, n_estimators=100, class_weight=\"balanced\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Training and testing\n",
    "rfc.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\nTrainings Score: %0.2f\" % (rfc.score(X_train, y_train)) + \"\\n\\n\")\n",
    "print(\"Test Score Report:\\n\")\n",
    "\n",
    "pred_test = rfc.predict(X_test)\n",
    "\n",
    "target_names = [\"Not popular\", \"Popular\", \"Very popular\"]\n",
    "print(classification_report(y_test, pred_test, target_names=target_names))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "print(f1_score(y_test, pred_test, average=\"weighted\"))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Calculating Feature Importance\n",
    "plt.rcParams.update({'figure.figsize': (16.0, 9.0)})\n",
    "plt.rcParams.update({'font.size': 15, 'grid.alpha': 1})\n",
    "\n",
    "\n",
    "importances = rfc.feature_importances_\n",
    "indices = np.argsort(importances)\n",
    "features = X.columns"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.title('Feature Importances')\n",
    "plt.barh(range(len(indices[53:])), importances[indices][53:], color=(0,0.69,0.5,1), align='center')\n",
    "plt.yticks(range(len(indices[53:])), [features[i] for i in indices[53:]])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.savefig('feature_imp.png')\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Cross Validation\n",
    "scores = cross_validate(rfc, X, y.values.ravel(), cv=5, scoring=('f1_micro', \"f1_macro\", 'accuracy', \"balanced_accuracy\"), return_train_score=True)\n",
    "\n",
    "print(\"test_f1_micro: %0.2f (+/- %0.2f)\" % (scores[\"test_f1_micro\"].mean(), scores[\"test_f1_micro\"].std() * 2))\n",
    "print(\"test_f1_macro: %0.2f (+/- %0.2f)\" % (scores[\"test_f1_macro\"].mean(), scores[\"test_f1_macro\"].std() * 2))\n",
    "print(\"test_accuracy: %0.2f (+/- %0.2f)\" % (scores[\"test_accuracy\"].mean(), scores[\"test_accuracy\"].std() * 2))\n",
    "print(\"test_balanced_accuracy: %0.2f (+/- %0.2f)\" % (scores[\"test_balanced_accuracy\"].mean(), scores[\"test_balanced_accuracy\"].std() * 2))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#validation\n",
    "pred_valid = rfc.predict(X_valid)\n",
    "\n",
    "print(\"Test Score Report:\\n\")\n",
    "print(classification_report(y_valid, pred_valid, target_names=target_names))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Additional Model Testing"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "modelx = imblearn.ensemble.BalancedBaggingClassifier(n_jobs=-1) #0.75 weighted avg\n",
    "modelx = imblearn.ensemble.BalancedRandomForestClassifier(class_weight=\"balanced\", n_jobs=-1) #0.73 weighted avg\n",
    "modelx = SVC() #too slow for size of dataset\n",
    "modelx = GaussianNB() #0.56 weighted avg\n",
    "modelx = DecisionTreeClassifier() #0.75 weighted avg\n",
    "modelx = BaggingClassifier(verbose=1, n_jobs=-1) #0.78 weighted avg, 0.79 Accuracy, 0.64 macro avg\n",
    "modelx = XGBRFClassifier(n_jobs=-1) #0.73 weighted avg\n",
    "\n",
    "modelx = KNeighborsClassifier(n_jobs=-1) #0.54 weighted avg\n",
    "modelx = XGBClassifier(seed=27, objective='multi:softprob', colsample_bytree=0.8, subsample=0.5,\n",
    "                       gamma=0, min_child_weight=1, max_depth=10, n_estimators=1000, learning_rate =0.1,\n",
    "                       sampling_method=\"gradient_based\", random_state=3, n_jobs=-1, tree_method='gpu_hist',\n",
    "                       predictor= 'gpu_predictor', verbosity=3) #0.80 weighted avg, 0.67 Accuracy, 0.80 macro avg"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "modelx.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "print(\"\\nTrainings Score: %0.2f\" % (modelx.score(X_train, y_train)) + \"\\n\\n\")\n",
    "print(\"Test Score Report:\\n\")\n",
    "\n",
    "pred_test = modelx.predict(X_test)\n",
    "\n",
    "target_names = [\"Not popular\", \"Popular\", \"Very popular\"]\n",
    "print(classification_report(y_test, pred_test, target_names=target_names))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "###GridSearchCV\n",
    "\n",
    "\n",
    "params = {\n",
    "            \"colsample_bytree\":[0.2,0.5,0.9],\n",
    "            \"subsample\":[0.3,0.5,0.8]\n",
    "           }\n",
    "\n",
    "gsearch = GridSearchCV(estimator=modelx,\n",
    "                       param_grid=params,\n",
    "                       cv=2,\n",
    "                       verbose=1,\n",
    "                       n_jobs=-1\n",
    "                       )\n",
    "\n",
    "gsearch.fit(X_train, y_train.values.ravel())\n",
    "gsearch.predict(X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier #No Increase in performance\n",
    "\n",
    "adb = AdaBoostClassifier(base_estimator=rfc, n_estimators=10, random_state=3)\n",
    "\n",
    "adb.fit(X_train, y_train)\n",
    "\n",
    "adb_pred = adb.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, adb_pred, target_names=target_names))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier #No Increase in performance\n",
    "\n",
    "gb = GradientBoostingClassifier(random_state=3, n_estimators=50)\n",
    "\n",
    "gb.fit(X_train, y_train)\n",
    "\n",
    "gb_pred = gb.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, gb_pred, target_names=target_names))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}